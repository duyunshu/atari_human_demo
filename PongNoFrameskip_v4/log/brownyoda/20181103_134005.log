2018-11-03 13:40:05,476 - atari_wrapper - INFO - ALE lives: 0
2018-11-03 13:40:05,477 - atari_wrapper - INFO - ALE frameskip: 1 / 1
2018-11-03 13:40:05,477 - atari_wrapper - INFO - ALE repeat_action_probability: 0.0
2018-11-03 13:40:05,477 - atari_wrapper - INFO - Gym action_space: Discrete(6)
2018-11-03 13:40:05,477 - atari_wrapper - INFO - AtariWrapper frameskip: 1
2018-11-03 13:40:05,477 - atari_wrapper - INFO - AtariWrapper noop_max: 30
2018-11-03 13:40:05,477 - atari_wrapper - INFO - EpisodicLifeEnv: True
2018-11-03 13:40:05,477 - atari_wrapper - INFO - FireResetEnv: True
2018-11-03 13:40:05,478 - atari_wrapper - INFO - WarpFrame: True
2018-11-03 13:40:05,478 - atari_wrapper - INFO - HumanDemoEnv: True
2018-11-03 13:40:05,803 - game_state - INFO - ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']
2018-11-03 13:44:16,031 - collect_demo - INFO - Duration: 0:04:09.352370
2018-11-03 13:44:16,032 - collect_demo - INFO - Total steps: 14961
2018-11-03 13:44:16,032 - collect_demo - INFO - Total reward: 5.0
2018-11-03 13:44:16,032 - collect_demo - INFO - Total Replay memory saved: 3745
2018-11-03 13:44:16,032 - replay_memory - INFO - Resizing replay memory...
2018-11-03 13:44:16,032 - replay_memory - DEBUG - Current specs: size=3745 max_steps=100000
2018-11-03 13:44:16,032 - replay_memory - DEBUG -     images shape: (100000, 84, 84)
2018-11-03 13:44:16,032 - replay_memory - DEBUG -     actions shape: (100000,)
2018-11-03 13:44:16,033 - replay_memory - DEBUG -     rewards shape: (100000,)
2018-11-03 13:44:16,033 - replay_memory - DEBUG -     terminal shape: (100000,)
2018-11-03 13:44:16,033 - replay_memory - DEBUG -     lives shape: (100000,)
2018-11-03 13:44:16,033 - replay_memory - DEBUG -     full_state shape: (100000, 1013)
2018-11-03 13:44:16,148 - replay_memory - INFO - Resizing completed!
2018-11-03 13:44:16,148 - replay_memory - DEBUG - Updated specs: size=3745 max_steps=3745
2018-11-03 13:44:16,149 - replay_memory - DEBUG -     images shape: (3745, 84, 84)
2018-11-03 13:44:16,149 - replay_memory - DEBUG -     actions shape: (3745,)
2018-11-03 13:44:16,149 - replay_memory - DEBUG -     rewards shape: (3745,)
2018-11-03 13:44:16,149 - replay_memory - DEBUG -     terminal shape: (3745,)
2018-11-03 13:44:16,149 - replay_memory - DEBUG -     lives shape: (3745,)
2018-11-03 13:44:16,150 - replay_memory - DEBUG -     full_state shape: (3745, 1013)
2018-11-03 13:44:16,157 - replay_memory - INFO - Compressing and saving replay memory...
2018-11-03 13:44:16,308 - replay_memory - INFO - Compressed and saved replay memory
2018-11-03 13:47:33,237 - collect_demo - INFO - Duration: 0:03:15.602277
2018-11-03 13:47:33,237 - collect_demo - INFO - Total steps: 11736
2018-11-03 13:47:33,238 - collect_demo - INFO - Total reward: -13.0
2018-11-03 13:47:33,238 - collect_demo - INFO - Total Replay memory saved: 2939
2018-11-03 13:47:33,238 - replay_memory - INFO - Resizing replay memory...
2018-11-03 13:47:33,238 - replay_memory - DEBUG - Current specs: size=2939 max_steps=100000
2018-11-03 13:47:33,238 - replay_memory - DEBUG -     images shape: (100000, 84, 84)
2018-11-03 13:47:33,238 - replay_memory - DEBUG -     actions shape: (100000,)
2018-11-03 13:47:33,238 - replay_memory - DEBUG -     rewards shape: (100000,)
2018-11-03 13:47:33,239 - replay_memory - DEBUG -     terminal shape: (100000,)
2018-11-03 13:47:33,239 - replay_memory - DEBUG -     lives shape: (100000,)
2018-11-03 13:47:33,239 - replay_memory - DEBUG -     full_state shape: (100000, 1013)
2018-11-03 13:47:33,351 - replay_memory - INFO - Resizing completed!
2018-11-03 13:47:33,351 - replay_memory - DEBUG - Updated specs: size=2939 max_steps=2939
2018-11-03 13:47:33,351 - replay_memory - DEBUG -     images shape: (2939, 84, 84)
2018-11-03 13:47:33,351 - replay_memory - DEBUG -     actions shape: (2939,)
2018-11-03 13:47:33,351 - replay_memory - DEBUG -     rewards shape: (2939,)
2018-11-03 13:47:33,351 - replay_memory - DEBUG -     terminal shape: (2939,)
2018-11-03 13:47:33,352 - replay_memory - DEBUG -     lives shape: (2939,)
2018-11-03 13:47:33,352 - replay_memory - DEBUG -     full_state shape: (2939, 1013)
2018-11-03 13:47:33,357 - replay_memory - INFO - Compressing and saving replay memory...
2018-11-03 13:47:33,475 - replay_memory - INFO - Compressed and saved replay memory
2018-11-03 13:47:33,494 - collect_demo - DEBUG - steps / episode: [14961, 11736]
2018-11-03 13:47:33,494 - collect_demo - DEBUG - reward / episode: [5.0, -13.0]
2018-11-03 13:47:33,494 - collect_demo - DEBUG - mean steps: 13348.5 / mean reward: -4.0
2018-11-03 13:47:33,494 - collect_demo - DEBUG - duration / episode:
2018-11-03 13:47:33,495 - collect_demo - DEBUG -     0:04:09.352370
2018-11-03 13:47:33,495 - collect_demo - DEBUG -     0:03:15.602277
2018-11-03 13:47:33,495 - collect_demo - DEBUG - total duration: 0:07:24.954647
2018-11-03 13:47:33,495 - collect_demo - DEBUG - mem size / episode: [3745, 2939]
2018-11-03 13:47:33,495 - collect_demo - DEBUG - total memory size: 6684
2018-11-03 13:47:33,496 - collect_demo - DEBUG - total # of episodes: 2
