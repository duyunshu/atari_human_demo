2018-11-03 13:47:59,500 - atari_wrapper - INFO - ALE lives: 5
2018-11-03 13:47:59,500 - atari_wrapper - INFO - ALE frameskip: 1 / 1
2018-11-03 13:47:59,500 - atari_wrapper - INFO - ALE repeat_action_probability: 0.0
2018-11-03 13:47:59,501 - atari_wrapper - INFO - Gym action_space: Discrete(4)
2018-11-03 13:47:59,501 - atari_wrapper - INFO - AtariWrapper frameskip: 1
2018-11-03 13:47:59,501 - atari_wrapper - INFO - AtariWrapper noop_max: 30
2018-11-03 13:47:59,501 - atari_wrapper - INFO - EpisodicLifeEnv: True
2018-11-03 13:47:59,501 - atari_wrapper - INFO - FireResetEnv: True
2018-11-03 13:47:59,501 - atari_wrapper - INFO - WarpFrame: True
2018-11-03 13:47:59,502 - atari_wrapper - INFO - HumanDemoEnv: True
2018-11-03 13:47:59,828 - game_state - INFO - ['NOOP', 'FIRE', 'RIGHT', 'LEFT']
2018-11-03 13:48:58,281 - collect_demo - INFO - Duration: 0:00:54.570427
2018-11-03 13:48:58,282 - collect_demo - INFO - Total steps: 3274
2018-11-03 13:48:58,282 - collect_demo - INFO - Total reward: 37.0
2018-11-03 13:48:58,282 - collect_demo - INFO - Total Replay memory saved: 842
2018-11-03 13:48:58,282 - replay_memory - INFO - Resizing replay memory...
2018-11-03 13:48:58,282 - replay_memory - DEBUG - Current specs: size=842 max_steps=100000
2018-11-03 13:48:58,282 - replay_memory - DEBUG -     images shape: (100000, 84, 84)
2018-11-03 13:48:58,283 - replay_memory - DEBUG -     actions shape: (100000,)
2018-11-03 13:48:58,283 - replay_memory - DEBUG -     rewards shape: (100000,)
2018-11-03 13:48:58,283 - replay_memory - DEBUG -     terminal shape: (100000,)
2018-11-03 13:48:58,283 - replay_memory - DEBUG -     lives shape: (100000,)
2018-11-03 13:48:58,283 - replay_memory - DEBUG -     full_state shape: (100000, 1021)
2018-11-03 13:48:58,387 - replay_memory - INFO - Resizing completed!
2018-11-03 13:48:58,388 - replay_memory - DEBUG - Updated specs: size=842 max_steps=842
2018-11-03 13:48:58,388 - replay_memory - DEBUG -     images shape: (842, 84, 84)
2018-11-03 13:48:58,388 - replay_memory - DEBUG -     actions shape: (842,)
2018-11-03 13:48:58,388 - replay_memory - DEBUG -     rewards shape: (842,)
2018-11-03 13:48:58,388 - replay_memory - DEBUG -     terminal shape: (842,)
2018-11-03 13:48:58,389 - replay_memory - DEBUG -     lives shape: (842,)
2018-11-03 13:48:58,389 - replay_memory - DEBUG -     full_state shape: (842, 1021)
2018-11-03 13:48:58,390 - replay_memory - INFO - Compressing and saving replay memory...
2018-11-03 13:48:58,430 - replay_memory - INFO - Compressed and saved replay memory
2018-11-03 13:50:27,020 - collect_demo - INFO - Duration: 0:01:25.635967
2018-11-03 13:50:27,020 - collect_demo - INFO - Total steps: 5138
2018-11-03 13:50:27,020 - collect_demo - INFO - Total reward: 57.0
2018-11-03 13:50:27,021 - collect_demo - INFO - Total Replay memory saved: 1308
2018-11-03 13:50:27,021 - replay_memory - INFO - Resizing replay memory...
2018-11-03 13:50:27,021 - replay_memory - DEBUG - Current specs: size=1308 max_steps=100000
2018-11-03 13:50:27,021 - replay_memory - DEBUG -     images shape: (100000, 84, 84)
2018-11-03 13:50:27,021 - replay_memory - DEBUG -     actions shape: (100000,)
2018-11-03 13:50:27,021 - replay_memory - DEBUG -     rewards shape: (100000,)
2018-11-03 13:50:27,021 - replay_memory - DEBUG -     terminal shape: (100000,)
2018-11-03 13:50:27,021 - replay_memory - DEBUG -     lives shape: (100000,)
2018-11-03 13:50:27,021 - replay_memory - DEBUG -     full_state shape: (100000, 1021)
2018-11-03 13:50:27,128 - replay_memory - INFO - Resizing completed!
2018-11-03 13:50:27,129 - replay_memory - DEBUG - Updated specs: size=1308 max_steps=1308
2018-11-03 13:50:27,129 - replay_memory - DEBUG -     images shape: (1308, 84, 84)
2018-11-03 13:50:27,129 - replay_memory - DEBUG -     actions shape: (1308,)
2018-11-03 13:50:27,129 - replay_memory - DEBUG -     rewards shape: (1308,)
2018-11-03 13:50:27,129 - replay_memory - DEBUG -     terminal shape: (1308,)
2018-11-03 13:50:27,129 - replay_memory - DEBUG -     lives shape: (1308,)
2018-11-03 13:50:27,129 - replay_memory - DEBUG -     full_state shape: (1308, 1021)
2018-11-03 13:50:27,132 - replay_memory - INFO - Compressing and saving replay memory...
2018-11-03 13:50:27,190 - replay_memory - INFO - Compressed and saved replay memory
2018-11-03 13:50:27,209 - collect_demo - DEBUG - steps / episode: [3274, 5138]
2018-11-03 13:50:27,209 - collect_demo - DEBUG - reward / episode: [37.0, 57.0]
2018-11-03 13:50:27,209 - collect_demo - DEBUG - mean steps: 4206.0 / mean reward: 47.0
2018-11-03 13:50:27,209 - collect_demo - DEBUG - duration / episode:
2018-11-03 13:50:27,210 - collect_demo - DEBUG -     0:00:54.570427
2018-11-03 13:50:27,210 - collect_demo - DEBUG -     0:01:25.635967
2018-11-03 13:50:27,210 - collect_demo - DEBUG - total duration: 0:02:20.206394
2018-11-03 13:50:27,210 - collect_demo - DEBUG - mem size / episode: [842, 1308]
2018-11-03 13:50:27,210 - collect_demo - DEBUG - total memory size: 2150
2018-11-03 13:50:27,210 - collect_demo - DEBUG - total # of episodes: 2
