2020-05-16 00:24:41,163 - atari_wrapper - INFO - ALE lives: 3
2020-05-16 00:24:41,163 - atari_wrapper - INFO - ALE frameskip: 1 / 1
2020-05-16 00:24:41,163 - atari_wrapper - INFO - ALE repeat_action_probability: 0.0
2020-05-16 00:24:41,163 - atari_wrapper - INFO - Gym action_space: Discrete(18)
2020-05-16 00:24:41,163 - atari_wrapper - INFO - AtariWrapper frameskip: 1
2020-05-16 00:24:41,164 - atari_wrapper - INFO - AtariWrapper noop_max: 30
2020-05-16 00:24:41,164 - atari_wrapper - INFO - EpisodicLifeEnv: True
2020-05-16 00:24:41,164 - atari_wrapper - INFO - FireResetEnv: True
2020-05-16 00:24:41,164 - atari_wrapper - INFO - WarpFrame: True
2020-05-16 00:24:41,164 - atari_wrapper - INFO - ALE sound: False
2020-05-16 00:24:41,164 - atari_wrapper - INFO - HumanDemoEnv: True
2020-05-16 00:24:41,188 - atari_wrapper - INFO - Joystick: Sony Interactive Entertainment Wireless Controller
2020-05-16 00:24:41,637 - game_state - INFO - ['NOOP', 'FIRE', 'UP', 'RIGHT', 'LEFT', 'DOWN', 'UPRIGHT', 'UPLEFT', 'DOWNRIGHT', 'DOWNLEFT', 'UPFIRE', 'RIGHTFIRE', 'LEFTFIRE', 'DOWNFIRE', 'UPRIGHTFIRE', 'UPLEFTFIRE', 'DOWNRIGHTFIRE', 'DOWNLEFTFIRE']
2020-05-16 00:27:43,343 - collect_demo - INFO - Duration: 0:03:01.641517
2020-05-16 00:27:43,344 - collect_demo - INFO - Total steps: 10754
2020-05-16 00:27:43,345 - collect_demo - INFO - Total reward: 5710.0
2020-05-16 00:27:43,349 - collect_demo - INFO - Total Replay memory saved: 2708
2020-05-16 00:27:43,349 - replay_memory - INFO - Resizing replay memory...
2020-05-16 00:27:43,350 - replay_memory - DEBUG - Current specs: size=2708 max_steps=100000
2020-05-16 00:27:43,350 - replay_memory - DEBUG -     images shape: (100000, 84, 84)
2020-05-16 00:27:43,351 - replay_memory - DEBUG -     actions shape: (100000,)
2020-05-16 00:27:43,351 - replay_memory - DEBUG -     rewards shape: (100000,)
2020-05-16 00:27:43,351 - replay_memory - DEBUG -     terminal shape: (100000,)
2020-05-16 00:27:43,352 - replay_memory - DEBUG -     lives shape: (100000,)
2020-05-16 00:27:43,352 - replay_memory - DEBUG -     full_state shape: (100000, 1017)
2020-05-16 00:27:43,453 - replay_memory - INFO - Resizing completed!
2020-05-16 00:27:43,454 - replay_memory - DEBUG - Updated specs: size=2708 max_steps=2708
2020-05-16 00:27:43,454 - replay_memory - DEBUG -     images shape: (2708, 84, 84)
2020-05-16 00:27:43,454 - replay_memory - DEBUG -     actions shape: (2708,)
2020-05-16 00:27:43,454 - replay_memory - DEBUG -     rewards shape: (2708,)
2020-05-16 00:27:43,454 - replay_memory - DEBUG -     terminal shape: (2708,)
2020-05-16 00:27:43,454 - replay_memory - DEBUG -     lives shape: (2708,)
2020-05-16 00:27:43,454 - replay_memory - DEBUG -     full_state shape: (2708, 1017)
2020-05-16 00:27:43,458 - replay_memory - INFO - Compressing and saving replay memory...
2020-05-16 00:27:43,564 - replay_memory - INFO - Compressed and saved replay memory
2020-05-16 00:27:46,379 - collect_demo - DEBUG - steps / episode: [10754]
2020-05-16 00:27:46,380 - collect_demo - DEBUG - reward / episode: [5710.0]
2020-05-16 00:27:46,381 - collect_demo - DEBUG - mean steps: 10754.0 / mean reward: 5710.0
2020-05-16 00:27:46,381 - collect_demo - DEBUG - duration / episode:
2020-05-16 00:27:46,382 - collect_demo - DEBUG -     0:03:01.641517
2020-05-16 00:27:46,382 - collect_demo - DEBUG - total duration: 0:03:01.641517
2020-05-16 00:27:46,382 - collect_demo - DEBUG - mem size / episode: [2708]
2020-05-16 00:27:46,383 - collect_demo - DEBUG - total memory size: 2708
2020-05-16 00:27:46,383 - collect_demo - DEBUG - total # of episodes: 1
2020-05-16 00:27:48,896 - atari_wrapper - INFO - ALE lives: 3
2020-05-16 00:27:48,896 - atari_wrapper - INFO - ALE frameskip: 1 / 1
2020-05-16 00:27:48,896 - atari_wrapper - INFO - ALE repeat_action_probability: 0.0
2020-05-16 00:27:48,896 - atari_wrapper - INFO - Gym action_space: Discrete(18)
2020-05-16 00:27:48,896 - atari_wrapper - INFO - AtariWrapper frameskip: 1
2020-05-16 00:27:48,897 - atari_wrapper - INFO - AtariWrapper noop_max: 30
2020-05-16 00:27:48,897 - atari_wrapper - INFO - EpisodicLifeEnv: True
2020-05-16 00:27:48,897 - atari_wrapper - INFO - FireResetEnv: True
2020-05-16 00:27:48,897 - atari_wrapper - INFO - WarpFrame: True
2020-05-16 00:27:48,897 - atari_wrapper - INFO - ALE sound: False
2020-05-16 00:27:48,897 - atari_wrapper - INFO - HumanDemoEnv: True
2020-05-16 00:27:48,920 - atari_wrapper - INFO - Joystick: Sony Interactive Entertainment Wireless Controller
2020-05-16 00:27:48,989 - game_state - INFO - ['NOOP', 'FIRE', 'UP', 'RIGHT', 'LEFT', 'DOWN', 'UPRIGHT', 'UPLEFT', 'DOWNRIGHT', 'DOWNLEFT', 'UPFIRE', 'RIGHTFIRE', 'LEFTFIRE', 'DOWNFIRE', 'UPRIGHTFIRE', 'UPLEFTFIRE', 'DOWNRIGHTFIRE', 'DOWNLEFTFIRE']
2020-05-16 00:29:32,505 - collect_demo - INFO - Duration: 0:01:43.460758
2020-05-16 00:29:32,506 - collect_demo - INFO - Total steps: 6056
2020-05-16 00:29:32,506 - collect_demo - INFO - Total reward: 2080.0
2020-05-16 00:29:32,506 - collect_demo - INFO - Total Replay memory saved: 1528
2020-05-16 00:29:32,506 - replay_memory - INFO - Resizing replay memory...
2020-05-16 00:29:32,506 - replay_memory - DEBUG - Current specs: size=1528 max_steps=100000
2020-05-16 00:29:32,507 - replay_memory - DEBUG -     images shape: (100000, 84, 84)
2020-05-16 00:29:32,507 - replay_memory - DEBUG -     actions shape: (100000,)
2020-05-16 00:29:32,507 - replay_memory - DEBUG -     rewards shape: (100000,)
2020-05-16 00:29:32,507 - replay_memory - DEBUG -     terminal shape: (100000,)
2020-05-16 00:29:32,507 - replay_memory - DEBUG -     lives shape: (100000,)
2020-05-16 00:29:32,507 - replay_memory - DEBUG -     full_state shape: (100000, 1017)
2020-05-16 00:29:32,592 - replay_memory - INFO - Resizing completed!
2020-05-16 00:29:32,592 - replay_memory - DEBUG - Updated specs: size=1528 max_steps=1528
2020-05-16 00:29:32,593 - replay_memory - DEBUG -     images shape: (1528, 84, 84)
2020-05-16 00:29:32,593 - replay_memory - DEBUG -     actions shape: (1528,)
2020-05-16 00:29:32,593 - replay_memory - DEBUG -     rewards shape: (1528,)
2020-05-16 00:29:32,593 - replay_memory - DEBUG -     terminal shape: (1528,)
2020-05-16 00:29:32,593 - replay_memory - DEBUG -     lives shape: (1528,)
2020-05-16 00:29:32,594 - replay_memory - DEBUG -     full_state shape: (1528, 1017)
2020-05-16 00:29:32,596 - replay_memory - INFO - Compressing and saving replay memory...
2020-05-16 00:29:32,665 - replay_memory - INFO - Compressed and saved replay memory
2020-05-16 00:29:33,601 - collect_demo - DEBUG - steps / episode: [6056]
2020-05-16 00:29:33,602 - collect_demo - DEBUG - reward / episode: [2080.0]
2020-05-16 00:29:33,602 - collect_demo - DEBUG - mean steps: 6056.0 / mean reward: 2080.0
2020-05-16 00:29:33,603 - collect_demo - DEBUG - duration / episode:
2020-05-16 00:29:33,603 - collect_demo - DEBUG -     0:01:43.460758
2020-05-16 00:29:33,603 - collect_demo - DEBUG - total duration: 0:01:43.460758
2020-05-16 00:29:33,604 - collect_demo - DEBUG - mem size / episode: [1528]
2020-05-16 00:29:33,604 - collect_demo - DEBUG - total memory size: 1528
2020-05-16 00:29:33,604 - collect_demo - DEBUG - total # of episodes: 1
2020-05-16 00:29:34,984 - atari_wrapper - INFO - ALE lives: 3
2020-05-16 00:29:34,985 - atari_wrapper - INFO - ALE frameskip: 1 / 1
2020-05-16 00:29:34,985 - atari_wrapper - INFO - ALE repeat_action_probability: 0.0
2020-05-16 00:29:34,985 - atari_wrapper - INFO - Gym action_space: Discrete(18)
2020-05-16 00:29:34,985 - atari_wrapper - INFO - AtariWrapper frameskip: 1
2020-05-16 00:29:34,985 - atari_wrapper - INFO - AtariWrapper noop_max: 30
2020-05-16 00:29:34,985 - atari_wrapper - INFO - EpisodicLifeEnv: True
2020-05-16 00:29:34,986 - atari_wrapper - INFO - FireResetEnv: True
2020-05-16 00:29:34,986 - atari_wrapper - INFO - WarpFrame: True
2020-05-16 00:29:34,986 - atari_wrapper - INFO - ALE sound: False
2020-05-16 00:29:34,986 - atari_wrapper - INFO - HumanDemoEnv: True
2020-05-16 00:29:35,000 - atari_wrapper - INFO - Joystick: Sony Interactive Entertainment Wireless Controller
2020-05-16 00:29:35,066 - game_state - INFO - ['NOOP', 'FIRE', 'UP', 'RIGHT', 'LEFT', 'DOWN', 'UPRIGHT', 'UPLEFT', 'DOWNRIGHT', 'DOWNLEFT', 'UPFIRE', 'RIGHTFIRE', 'LEFTFIRE', 'DOWNFIRE', 'UPRIGHTFIRE', 'UPLEFTFIRE', 'DOWNRIGHTFIRE', 'DOWNLEFTFIRE']
2020-05-16 00:46:34,222 - collect_demo - INFO - Duration: 0:16:59.082393
2020-05-16 00:46:34,223 - collect_demo - INFO - Total steps: 14783
2020-05-16 00:46:34,224 - collect_demo - INFO - Total reward: 7850.0
2020-05-16 00:46:34,225 - collect_demo - INFO - Total Replay memory saved: 3715
2020-05-16 00:46:34,226 - replay_memory - INFO - Resizing replay memory...
2020-05-16 00:46:34,227 - replay_memory - DEBUG - Current specs: size=3715 max_steps=100000
2020-05-16 00:46:34,228 - replay_memory - DEBUG -     images shape: (100000, 84, 84)
2020-05-16 00:46:34,228 - replay_memory - DEBUG -     actions shape: (100000,)
2020-05-16 00:46:34,229 - replay_memory - DEBUG -     rewards shape: (100000,)
2020-05-16 00:46:34,229 - replay_memory - DEBUG -     terminal shape: (100000,)
2020-05-16 00:46:34,229 - replay_memory - DEBUG -     lives shape: (100000,)
2020-05-16 00:46:34,229 - replay_memory - DEBUG -     full_state shape: (100000, 1017)
2020-05-16 00:46:34,319 - replay_memory - INFO - Resizing completed!
2020-05-16 00:46:34,319 - replay_memory - DEBUG - Updated specs: size=3715 max_steps=3715
2020-05-16 00:46:34,320 - replay_memory - DEBUG -     images shape: (3715, 84, 84)
2020-05-16 00:46:34,320 - replay_memory - DEBUG -     actions shape: (3715,)
2020-05-16 00:46:34,320 - replay_memory - DEBUG -     rewards shape: (3715,)
2020-05-16 00:46:34,320 - replay_memory - DEBUG -     terminal shape: (3715,)
2020-05-16 00:46:34,321 - replay_memory - DEBUG -     lives shape: (3715,)
2020-05-16 00:46:34,321 - replay_memory - DEBUG -     full_state shape: (3715, 1017)
2020-05-16 00:46:34,327 - replay_memory - INFO - Compressing and saving replay memory...
2020-05-16 00:46:34,480 - replay_memory - INFO - Compressed and saved replay memory
2020-05-16 00:46:37,095 - collect_demo - DEBUG - steps / episode: [14783]
2020-05-16 00:46:37,097 - collect_demo - DEBUG - reward / episode: [7850.0]
2020-05-16 00:46:37,098 - collect_demo - DEBUG - mean steps: 14783.0 / mean reward: 7850.0
2020-05-16 00:46:37,099 - collect_demo - DEBUG - duration / episode:
2020-05-16 00:46:37,100 - collect_demo - DEBUG -     0:16:59.082393
2020-05-16 00:46:37,100 - collect_demo - DEBUG - total duration: 0:16:59.082393
2020-05-16 00:46:37,101 - collect_demo - DEBUG - mem size / episode: [3715]
2020-05-16 00:46:37,102 - collect_demo - DEBUG - total memory size: 3715
2020-05-16 00:46:37,102 - collect_demo - DEBUG - total # of episodes: 1
