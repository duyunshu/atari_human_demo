2018-11-03 23:36:19,864 - atari_wrapper - INFO - ALE lives: 3
2018-11-03 23:36:19,864 - atari_wrapper - INFO - ALE frameskip: 1 / 1
2018-11-03 23:36:19,864 - atari_wrapper - INFO - ALE repeat_action_probability: 0.0
2018-11-03 23:36:19,865 - atari_wrapper - INFO - Gym action_space: Discrete(6)
2018-11-03 23:36:19,865 - atari_wrapper - INFO - AtariWrapper frameskip: 1
2018-11-03 23:36:19,865 - atari_wrapper - INFO - AtariWrapper noop_max: 30
2018-11-03 23:36:19,865 - atari_wrapper - INFO - EpisodicLifeEnv: True
2018-11-03 23:36:19,865 - atari_wrapper - INFO - FireResetEnv: True
2018-11-03 23:36:19,865 - atari_wrapper - INFO - WarpFrame: True
2018-11-03 23:36:19,865 - atari_wrapper - INFO - HumanDemoEnv: True
2018-11-03 23:36:20,198 - game_state - INFO - ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']
2018-11-03 23:38:29,446 - collect_demo - INFO - Duration: 0:01:34.702672
2018-11-03 23:38:29,446 - collect_demo - INFO - Total steps: 5682
2018-11-03 23:38:29,446 - collect_demo - INFO - Total reward: 880.0
2018-11-03 23:38:29,446 - collect_demo - INFO - Total Replay memory saved: 1907
2018-11-03 23:38:29,446 - replay_memory - INFO - Resizing replay memory...
2018-11-03 23:38:29,446 - replay_memory - DEBUG - Current specs: size=1907 max_steps=100000
2018-11-03 23:38:29,447 - replay_memory - DEBUG -     images shape: (100000, 84, 84)
2018-11-03 23:38:29,447 - replay_memory - DEBUG -     actions shape: (100000,)
2018-11-03 23:38:29,447 - replay_memory - DEBUG -     rewards shape: (100000,)
2018-11-03 23:38:29,447 - replay_memory - DEBUG -     terminal shape: (100000,)
2018-11-03 23:38:29,447 - replay_memory - DEBUG -     lives shape: (100000,)
2018-11-03 23:38:29,447 - replay_memory - DEBUG -     full_state shape: (100000, 1017)
2018-11-03 23:38:29,554 - replay_memory - INFO - Resizing completed!
2018-11-03 23:38:29,554 - replay_memory - DEBUG - Updated specs: size=1907 max_steps=1907
2018-11-03 23:38:29,554 - replay_memory - DEBUG -     images shape: (1907, 84, 84)
2018-11-03 23:38:29,554 - replay_memory - DEBUG -     actions shape: (1907,)
2018-11-03 23:38:29,554 - replay_memory - DEBUG -     rewards shape: (1907,)
2018-11-03 23:38:29,554 - replay_memory - DEBUG -     terminal shape: (1907,)
2018-11-03 23:38:29,555 - replay_memory - DEBUG -     lives shape: (1907,)
2018-11-03 23:38:29,555 - replay_memory - DEBUG -     full_state shape: (1907, 1017)
2018-11-03 23:38:29,558 - replay_memory - INFO - Compressing and saving replay memory...
2018-11-03 23:38:29,647 - replay_memory - INFO - Compressed and saved replay memory
2018-11-03 23:40:40,814 - collect_demo - INFO - Duration: 0:02:09.385751
2018-11-03 23:40:40,815 - collect_demo - INFO - Total steps: 7763
2018-11-03 23:40:40,815 - collect_demo - INFO - Total reward: 1235.0
2018-11-03 23:40:40,815 - collect_demo - INFO - Total Replay memory saved: 2597
2018-11-03 23:40:40,815 - replay_memory - INFO - Resizing replay memory...
2018-11-03 23:40:40,815 - replay_memory - DEBUG - Current specs: size=2597 max_steps=100000
2018-11-03 23:40:40,815 - replay_memory - DEBUG -     images shape: (100000, 84, 84)
2018-11-03 23:40:40,815 - replay_memory - DEBUG -     actions shape: (100000,)
2018-11-03 23:40:40,816 - replay_memory - DEBUG -     rewards shape: (100000,)
2018-11-03 23:40:40,816 - replay_memory - DEBUG -     terminal shape: (100000,)
2018-11-03 23:40:40,816 - replay_memory - DEBUG -     lives shape: (100000,)
2018-11-03 23:40:40,816 - replay_memory - DEBUG -     full_state shape: (100000, 1017)
2018-11-03 23:40:40,926 - replay_memory - INFO - Resizing completed!
2018-11-03 23:40:40,927 - replay_memory - DEBUG - Updated specs: size=2597 max_steps=2597
2018-11-03 23:40:40,927 - replay_memory - DEBUG -     images shape: (2597, 84, 84)
2018-11-03 23:40:40,927 - replay_memory - DEBUG -     actions shape: (2597,)
2018-11-03 23:40:40,927 - replay_memory - DEBUG -     rewards shape: (2597,)
2018-11-03 23:40:40,927 - replay_memory - DEBUG -     terminal shape: (2597,)
2018-11-03 23:40:40,927 - replay_memory - DEBUG -     lives shape: (2597,)
2018-11-03 23:40:40,928 - replay_memory - DEBUG -     full_state shape: (2597, 1017)
2018-11-03 23:40:40,932 - replay_memory - INFO - Compressing and saving replay memory...
2018-11-03 23:40:41,049 - replay_memory - INFO - Compressed and saved replay memory
2018-11-03 23:40:41,068 - collect_demo - DEBUG - steps / episode: [5682, 7763]
2018-11-03 23:40:41,069 - collect_demo - DEBUG - reward / episode: [880.0, 1235.0]
2018-11-03 23:40:41,069 - collect_demo - DEBUG - mean steps: 6722.5 / mean reward: 1057.5
2018-11-03 23:40:41,069 - collect_demo - DEBUG - duration / episode:
2018-11-03 23:40:41,069 - collect_demo - DEBUG -     0:01:34.702672
2018-11-03 23:40:41,069 - collect_demo - DEBUG -     0:02:09.385751
2018-11-03 23:40:41,069 - collect_demo - DEBUG - total duration: 0:03:44.088423
2018-11-03 23:40:41,070 - collect_demo - DEBUG - mem size / episode: [1907, 2597]
2018-11-03 23:40:41,070 - collect_demo - DEBUG - total memory size: 4504
2018-11-03 23:40:41,070 - collect_demo - DEBUG - total # of episodes: 2
