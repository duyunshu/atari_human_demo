2018-11-03 23:47:00,705 - atari_wrapper - INFO - ALE lives: 3
2018-11-03 23:47:00,705 - atari_wrapper - INFO - ALE frameskip: 1 / 1
2018-11-03 23:47:00,705 - atari_wrapper - INFO - ALE repeat_action_probability: 0.0
2018-11-03 23:47:00,705 - atari_wrapper - INFO - Gym action_space: Discrete(6)
2018-11-03 23:47:00,705 - atari_wrapper - INFO - AtariWrapper frameskip: 1
2018-11-03 23:47:00,705 - atari_wrapper - INFO - AtariWrapper noop_max: 30
2018-11-03 23:47:00,706 - atari_wrapper - INFO - EpisodicLifeEnv: True
2018-11-03 23:47:00,706 - atari_wrapper - INFO - FireResetEnv: True
2018-11-03 23:47:00,706 - atari_wrapper - INFO - WarpFrame: True
2018-11-03 23:47:00,706 - atari_wrapper - INFO - HumanDemoEnv: True
2018-11-03 23:47:01,038 - game_state - INFO - ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']
2018-11-03 23:48:21,976 - collect_demo - INFO - Duration: 0:01:18.969049
2018-11-03 23:48:21,977 - collect_demo - INFO - Total steps: 4738
2018-11-03 23:48:21,977 - collect_demo - INFO - Total reward: 600.0
2018-11-03 23:48:21,977 - collect_demo - INFO - Total Replay memory saved: 1589
2018-11-03 23:48:21,977 - replay_memory - INFO - Resizing replay memory...
2018-11-03 23:48:21,977 - replay_memory - DEBUG - Current specs: size=1589 max_steps=100000
2018-11-03 23:48:21,977 - replay_memory - DEBUG -     images shape: (100000, 84, 84)
2018-11-03 23:48:21,977 - replay_memory - DEBUG -     actions shape: (100000,)
2018-11-03 23:48:21,978 - replay_memory - DEBUG -     rewards shape: (100000,)
2018-11-03 23:48:21,978 - replay_memory - DEBUG -     terminal shape: (100000,)
2018-11-03 23:48:21,978 - replay_memory - DEBUG -     lives shape: (100000,)
2018-11-03 23:48:21,978 - replay_memory - DEBUG -     full_state shape: (100000, 1017)
2018-11-03 23:48:22,086 - replay_memory - INFO - Resizing completed!
2018-11-03 23:48:22,086 - replay_memory - DEBUG - Updated specs: size=1589 max_steps=1589
2018-11-03 23:48:22,087 - replay_memory - DEBUG -     images shape: (1589, 84, 84)
2018-11-03 23:48:22,087 - replay_memory - DEBUG -     actions shape: (1589,)
2018-11-03 23:48:22,087 - replay_memory - DEBUG -     rewards shape: (1589,)
2018-11-03 23:48:22,087 - replay_memory - DEBUG -     terminal shape: (1589,)
2018-11-03 23:48:22,087 - replay_memory - DEBUG -     lives shape: (1589,)
2018-11-03 23:48:22,087 - replay_memory - DEBUG -     full_state shape: (1589, 1017)
2018-11-03 23:48:22,090 - replay_memory - INFO - Compressing and saving replay memory...
2018-11-03 23:48:22,164 - replay_memory - INFO - Compressed and saved replay memory
2018-11-04 00:16:39,094 - collect_demo - INFO - Duration: 0:03:31.219698
2018-11-04 00:16:39,094 - collect_demo - INFO - Total steps: 12673
2018-11-04 00:16:39,094 - collect_demo - INFO - Total reward: 1840.0
2018-11-04 00:16:39,094 - collect_demo - INFO - Total Replay memory saved: 4238
2018-11-04 00:16:39,095 - replay_memory - INFO - Resizing replay memory...
2018-11-04 00:16:39,095 - replay_memory - DEBUG - Current specs: size=4238 max_steps=100000
2018-11-04 00:16:39,095 - replay_memory - DEBUG -     images shape: (100000, 84, 84)
2018-11-04 00:16:39,095 - replay_memory - DEBUG -     actions shape: (100000,)
2018-11-04 00:16:39,095 - replay_memory - DEBUG -     rewards shape: (100000,)
2018-11-04 00:16:39,095 - replay_memory - DEBUG -     terminal shape: (100000,)
2018-11-04 00:16:39,096 - replay_memory - DEBUG -     lives shape: (100000,)
2018-11-04 00:16:39,096 - replay_memory - DEBUG -     full_state shape: (100000, 1017)
2018-11-04 00:16:39,215 - replay_memory - INFO - Resizing completed!
2018-11-04 00:16:39,215 - replay_memory - DEBUG - Updated specs: size=4238 max_steps=4238
2018-11-04 00:16:39,215 - replay_memory - DEBUG -     images shape: (4238, 84, 84)
2018-11-04 00:16:39,216 - replay_memory - DEBUG -     actions shape: (4238,)
2018-11-04 00:16:39,216 - replay_memory - DEBUG -     rewards shape: (4238,)
2018-11-04 00:16:39,216 - replay_memory - DEBUG -     terminal shape: (4238,)
2018-11-04 00:16:39,216 - replay_memory - DEBUG -     lives shape: (4238,)
2018-11-04 00:16:39,216 - replay_memory - DEBUG -     full_state shape: (4238, 1017)
2018-11-04 00:16:39,223 - replay_memory - INFO - Compressing and saving replay memory...
2018-11-04 00:16:39,411 - replay_memory - INFO - Compressed and saved replay memory
2018-11-04 00:16:39,431 - collect_demo - DEBUG - steps / episode: [4738, 12673]
2018-11-04 00:16:39,432 - collect_demo - DEBUG - reward / episode: [600.0, 1840.0]
2018-11-04 00:16:39,432 - collect_demo - DEBUG - mean steps: 8705.5 / mean reward: 1220.0
2018-11-04 00:16:39,432 - collect_demo - DEBUG - duration / episode:
2018-11-04 00:16:39,432 - collect_demo - DEBUG -     0:01:18.969049
2018-11-04 00:16:39,432 - collect_demo - DEBUG -     0:03:31.219698
2018-11-04 00:16:39,433 - collect_demo - DEBUG - total duration: 0:04:50.188747
2018-11-04 00:16:39,433 - collect_demo - DEBUG - mem size / episode: [1589, 4238]
2018-11-04 00:16:39,433 - collect_demo - DEBUG - total memory size: 5827
2018-11-04 00:16:39,433 - collect_demo - DEBUG - total # of episodes: 2
