2018-11-03 23:44:36,710 - atari_wrapper - INFO - ALE lives: 3
2018-11-03 23:44:36,710 - atari_wrapper - INFO - ALE frameskip: 1 / 1
2018-11-03 23:44:36,710 - atari_wrapper - INFO - ALE repeat_action_probability: 0.0
2018-11-03 23:44:36,710 - atari_wrapper - INFO - Gym action_space: Discrete(6)
2018-11-03 23:44:36,710 - atari_wrapper - INFO - AtariWrapper frameskip: 1
2018-11-03 23:44:36,710 - atari_wrapper - INFO - AtariWrapper noop_max: 30
2018-11-03 23:44:36,711 - atari_wrapper - INFO - EpisodicLifeEnv: True
2018-11-03 23:44:36,711 - atari_wrapper - INFO - FireResetEnv: True
2018-11-03 23:44:36,711 - atari_wrapper - INFO - WarpFrame: True
2018-11-03 23:44:36,711 - atari_wrapper - INFO - HumanDemoEnv: True
2018-11-03 23:44:37,039 - game_state - INFO - ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']
2018-11-03 23:45:50,488 - collect_demo - INFO - Duration: 0:01:12.136014
2018-11-03 23:45:50,488 - collect_demo - INFO - Total steps: 4328
2018-11-03 23:45:50,488 - collect_demo - INFO - Total reward: 800.0
2018-11-03 23:45:50,488 - collect_demo - INFO - Total Replay memory saved: 1456
2018-11-03 23:45:50,489 - replay_memory - INFO - Resizing replay memory...
2018-11-03 23:45:50,489 - replay_memory - DEBUG - Current specs: size=1456 max_steps=100000
2018-11-03 23:45:50,489 - replay_memory - DEBUG -     images shape: (100000, 84, 84)
2018-11-03 23:45:50,489 - replay_memory - DEBUG -     actions shape: (100000,)
2018-11-03 23:45:50,489 - replay_memory - DEBUG -     rewards shape: (100000,)
2018-11-03 23:45:50,489 - replay_memory - DEBUG -     terminal shape: (100000,)
2018-11-03 23:45:50,489 - replay_memory - DEBUG -     lives shape: (100000,)
2018-11-03 23:45:50,489 - replay_memory - DEBUG -     full_state shape: (100000, 1017)
2018-11-03 23:45:50,597 - replay_memory - INFO - Resizing completed!
2018-11-03 23:45:50,597 - replay_memory - DEBUG - Updated specs: size=1456 max_steps=1456
2018-11-03 23:45:50,597 - replay_memory - DEBUG -     images shape: (1456, 84, 84)
2018-11-03 23:45:50,598 - replay_memory - DEBUG -     actions shape: (1456,)
2018-11-03 23:45:50,598 - replay_memory - DEBUG -     rewards shape: (1456,)
2018-11-03 23:45:50,598 - replay_memory - DEBUG -     terminal shape: (1456,)
2018-11-03 23:45:50,598 - replay_memory - DEBUG -     lives shape: (1456,)
2018-11-03 23:45:50,598 - replay_memory - DEBUG -     full_state shape: (1456, 1017)
2018-11-03 23:45:50,601 - replay_memory - INFO - Compressing and saving replay memory...
2018-11-03 23:45:50,669 - replay_memory - INFO - Compressed and saved replay memory
2018-11-03 23:46:56,507 - collect_demo - INFO - Duration: 0:01:04.621145
2018-11-03 23:46:56,507 - collect_demo - INFO - Total steps: 3877
2018-11-03 23:46:56,507 - collect_demo - INFO - Total reward: 545.0
2018-11-03 23:46:56,507 - collect_demo - INFO - Total Replay memory saved: 1307
2018-11-03 23:46:56,508 - replay_memory - INFO - Resizing replay memory...
2018-11-03 23:46:56,508 - replay_memory - DEBUG - Current specs: size=1307 max_steps=100000
2018-11-03 23:46:56,508 - replay_memory - DEBUG -     images shape: (100000, 84, 84)
2018-11-03 23:46:56,508 - replay_memory - DEBUG -     actions shape: (100000,)
2018-11-03 23:46:56,508 - replay_memory - DEBUG -     rewards shape: (100000,)
2018-11-03 23:46:56,509 - replay_memory - DEBUG -     terminal shape: (100000,)
2018-11-03 23:46:56,509 - replay_memory - DEBUG -     lives shape: (100000,)
2018-11-03 23:46:56,509 - replay_memory - DEBUG -     full_state shape: (100000, 1017)
2018-11-03 23:46:56,685 - replay_memory - INFO - Resizing completed!
2018-11-03 23:46:56,685 - replay_memory - DEBUG - Updated specs: size=1307 max_steps=1307
2018-11-03 23:46:56,685 - replay_memory - DEBUG -     images shape: (1307, 84, 84)
2018-11-03 23:46:56,686 - replay_memory - DEBUG -     actions shape: (1307,)
2018-11-03 23:46:56,686 - replay_memory - DEBUG -     rewards shape: (1307,)
2018-11-03 23:46:56,686 - replay_memory - DEBUG -     terminal shape: (1307,)
2018-11-03 23:46:56,686 - replay_memory - DEBUG -     lives shape: (1307,)
2018-11-03 23:46:56,686 - replay_memory - DEBUG -     full_state shape: (1307, 1017)
2018-11-03 23:46:56,689 - replay_memory - INFO - Compressing and saving replay memory...
2018-11-03 23:46:56,749 - replay_memory - INFO - Compressed and saved replay memory
2018-11-03 23:46:56,771 - collect_demo - DEBUG - steps / episode: [4328, 3877]
2018-11-03 23:46:56,771 - collect_demo - DEBUG - reward / episode: [800.0, 545.0]
2018-11-03 23:46:56,772 - collect_demo - DEBUG - mean steps: 4102.5 / mean reward: 672.5
2018-11-03 23:46:56,772 - collect_demo - DEBUG - duration / episode:
2018-11-03 23:46:56,772 - collect_demo - DEBUG -     0:01:12.136014
2018-11-03 23:46:56,772 - collect_demo - DEBUG -     0:01:04.621145
2018-11-03 23:46:56,772 - collect_demo - DEBUG - total duration: 0:02:16.757159
2018-11-03 23:46:56,772 - collect_demo - DEBUG - mem size / episode: [1456, 1307]
2018-11-03 23:46:56,773 - collect_demo - DEBUG - total memory size: 2763
2018-11-03 23:46:56,773 - collect_demo - DEBUG - total # of episodes: 2
