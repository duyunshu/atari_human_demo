2018-11-03 23:41:06,404 - atari_wrapper - INFO - ALE lives: 3
2018-11-03 23:41:06,405 - atari_wrapper - INFO - ALE frameskip: 1 / 1
2018-11-03 23:41:06,405 - atari_wrapper - INFO - ALE repeat_action_probability: 0.0
2018-11-03 23:41:06,405 - atari_wrapper - INFO - Gym action_space: Discrete(6)
2018-11-03 23:41:06,405 - atari_wrapper - INFO - AtariWrapper frameskip: 1
2018-11-03 23:41:06,405 - atari_wrapper - INFO - AtariWrapper noop_max: 30
2018-11-03 23:41:06,405 - atari_wrapper - INFO - EpisodicLifeEnv: True
2018-11-03 23:41:06,405 - atari_wrapper - INFO - FireResetEnv: True
2018-11-03 23:41:06,406 - atari_wrapper - INFO - WarpFrame: True
2018-11-03 23:41:06,406 - atari_wrapper - INFO - HumanDemoEnv: True
2018-11-03 23:41:06,738 - game_state - INFO - ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']
2018-11-03 23:42:22,878 - collect_demo - INFO - Duration: 0:01:14.919088
2018-11-03 23:42:22,879 - collect_demo - INFO - Total steps: 4495
2018-11-03 23:42:22,879 - collect_demo - INFO - Total reward: 805.0
2018-11-03 23:42:22,879 - collect_demo - INFO - Total Replay memory saved: 1508
2018-11-03 23:42:22,879 - replay_memory - INFO - Resizing replay memory...
2018-11-03 23:42:22,879 - replay_memory - DEBUG - Current specs: size=1508 max_steps=100000
2018-11-03 23:42:22,879 - replay_memory - DEBUG -     images shape: (100000, 84, 84)
2018-11-03 23:42:22,879 - replay_memory - DEBUG -     actions shape: (100000,)
2018-11-03 23:42:22,879 - replay_memory - DEBUG -     rewards shape: (100000,)
2018-11-03 23:42:22,880 - replay_memory - DEBUG -     terminal shape: (100000,)
2018-11-03 23:42:22,880 - replay_memory - DEBUG -     lives shape: (100000,)
2018-11-03 23:42:22,880 - replay_memory - DEBUG -     full_state shape: (100000, 1017)
2018-11-03 23:42:22,988 - replay_memory - INFO - Resizing completed!
2018-11-03 23:42:22,988 - replay_memory - DEBUG - Updated specs: size=1508 max_steps=1508
2018-11-03 23:42:22,988 - replay_memory - DEBUG -     images shape: (1508, 84, 84)
2018-11-03 23:42:22,988 - replay_memory - DEBUG -     actions shape: (1508,)
2018-11-03 23:42:22,988 - replay_memory - DEBUG -     rewards shape: (1508,)
2018-11-03 23:42:22,988 - replay_memory - DEBUG -     terminal shape: (1508,)
2018-11-03 23:42:22,989 - replay_memory - DEBUG -     lives shape: (1508,)
2018-11-03 23:42:22,989 - replay_memory - DEBUG -     full_state shape: (1508, 1017)
2018-11-03 23:42:22,992 - replay_memory - INFO - Compressing and saving replay memory...
2018-11-03 23:42:23,063 - replay_memory - INFO - Compressed and saved replay memory
2018-11-03 23:44:13,736 - collect_demo - INFO - Duration: 0:01:49.552515
2018-11-03 23:44:13,736 - collect_demo - INFO - Total steps: 6573
2018-11-03 23:44:13,736 - collect_demo - INFO - Total reward: 870.0
2018-11-03 23:44:13,737 - collect_demo - INFO - Total Replay memory saved: 2205
2018-11-03 23:44:13,737 - replay_memory - INFO - Resizing replay memory...
2018-11-03 23:44:13,737 - replay_memory - DEBUG - Current specs: size=2205 max_steps=100000
2018-11-03 23:44:13,737 - replay_memory - DEBUG -     images shape: (100000, 84, 84)
2018-11-03 23:44:13,737 - replay_memory - DEBUG -     actions shape: (100000,)
2018-11-03 23:44:13,737 - replay_memory - DEBUG -     rewards shape: (100000,)
2018-11-03 23:44:13,738 - replay_memory - DEBUG -     terminal shape: (100000,)
2018-11-03 23:44:13,738 - replay_memory - DEBUG -     lives shape: (100000,)
2018-11-03 23:44:13,738 - replay_memory - DEBUG -     full_state shape: (100000, 1017)
2018-11-03 23:44:13,847 - replay_memory - INFO - Resizing completed!
2018-11-03 23:44:13,847 - replay_memory - DEBUG - Updated specs: size=2205 max_steps=2205
2018-11-03 23:44:13,847 - replay_memory - DEBUG -     images shape: (2205, 84, 84)
2018-11-03 23:44:13,847 - replay_memory - DEBUG -     actions shape: (2205,)
2018-11-03 23:44:13,847 - replay_memory - DEBUG -     rewards shape: (2205,)
2018-11-03 23:44:13,848 - replay_memory - DEBUG -     terminal shape: (2205,)
2018-11-03 23:44:13,848 - replay_memory - DEBUG -     lives shape: (2205,)
2018-11-03 23:44:13,848 - replay_memory - DEBUG -     full_state shape: (2205, 1017)
2018-11-03 23:44:13,852 - replay_memory - INFO - Compressing and saving replay memory...
2018-11-03 23:44:13,953 - replay_memory - INFO - Compressed and saved replay memory
2018-11-03 23:44:13,972 - collect_demo - DEBUG - steps / episode: [4495, 6573]
2018-11-03 23:44:13,972 - collect_demo - DEBUG - reward / episode: [805.0, 870.0]
2018-11-03 23:44:13,972 - collect_demo - DEBUG - mean steps: 5534.0 / mean reward: 837.5
2018-11-03 23:44:13,972 - collect_demo - DEBUG - duration / episode:
2018-11-03 23:44:13,972 - collect_demo - DEBUG -     0:01:14.919088
2018-11-03 23:44:13,973 - collect_demo - DEBUG -     0:01:49.552515
2018-11-03 23:44:13,973 - collect_demo - DEBUG - total duration: 0:03:04.471603
2018-11-03 23:44:13,973 - collect_demo - DEBUG - mem size / episode: [1508, 2205]
2018-11-03 23:44:13,973 - collect_demo - DEBUG - total memory size: 3713
2018-11-03 23:44:13,973 - collect_demo - DEBUG - total # of episodes: 2
